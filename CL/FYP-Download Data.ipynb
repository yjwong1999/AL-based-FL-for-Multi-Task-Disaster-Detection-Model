{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c745934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-03 03:01:21.994182: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import timeit\n",
    "import shutil\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from yolov3_tf2.convert import convert_weight\n",
    "\n",
    "\n",
    "# define the flags\n",
    "class Flags:\n",
    "    def __init__(self):\n",
    "        self.size = 416\n",
    "        self.num_classes = 1\n",
    "        self.yolo_max_boxes = 100\n",
    "        self.yolo_iou_threshold = 0.5\n",
    "        self.yolo_score_threshold = 0.5\n",
    "        \n",
    "        self.transfer = 'darknet'\n",
    "        self.root = os.getcwd()\n",
    "        self.ori_weight_path = os.path.join(self.root, 'data/yolov3.weights')\n",
    "        self.new_weigth_path = os.path.join(self.root, 'checkpoints/yolov3.tf')\n",
    "        \n",
    "        self.epochs = 100\n",
    "        self.mini_batch_size = 8\n",
    "        self.num_grad_accumulates = 8 #8 #16\n",
    "        self.learning_rate = 1e-3\n",
    "        self.num_classes = 1\n",
    "\n",
    "        self.mode = 'eager_fit'\n",
    "\n",
    "FLAGS = Flags()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbf52ca",
   "metadata": {},
   "source": [
    "# Get the Pretrained Weights from the Pretrained YOLOv3\n",
    "The pretrained YOLOv3 weights are acquired from the link below: <br>\n",
    "https://pjreddie.com/media/files/yolov3.weights <br>\n",
    "\n",
    "All the sub-layers/sub-models in the YOLOv3 are stated below: <br>\n",
    "- 'yolo_darknet', <br>\n",
    "- 'yolo_conv_0', <br>\n",
    "- 'yolo_conv_1', <br>\n",
    "- 'yolo_conv_2', <br>\n",
    "- 'yolo_output_0', <br>\n",
    "- 'yolo_output_1', <br>\n",
    "- 'yolo_output_2', <br>\n",
    "\n",
    "Choose the layers to be transfered learning in the code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47856f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory \"/home/tham/Documents/fyp_yijie/data\" existed\n",
      "Directory \"/home/tham/Documents/fyp_yijie/checkpoints\" existed\n",
      "Weight and Checkpoints files existed\n"
     ]
    }
   ],
   "source": [
    "# get the yolo weights and save to data/yolov3.weights\n",
    "_path = os.path.join(FLAGS.root, 'data')\n",
    "if not os.path.isdir(_path):\n",
    "    os.mkdir(_path)\n",
    "    print(f'Created directory \"{_path}\"')\n",
    "else:\n",
    "    print(f'Directory \"{_path}\" existed')\n",
    "    \n",
    "_path = os.path.join(FLAGS.root, 'checkpoints')    \n",
    "if not os.path.isdir(_path):\n",
    "    os.mkdir(_path)\n",
    "    print(f'Created directory \"{_path}\"')\n",
    "else:\n",
    "    print(f'Directory \"{_path}\" existed')\n",
    "\n",
    "if not os.path.isfile(FLAGS.ori_weight_path):  \n",
    "    print('Getting ready the weights of the pre-trained model...')\n",
    "    os.system(f'wget https://pjreddie.com/media/files/yolov3.weights -O {FLAGS.ori_weight_path}')\n",
    "\n",
    "    # convert the yolo weights file\n",
    "    convert_weight(ori_weight_path = FLAGS.ori_weight_path, \n",
    "                   new_weigth_path = FLAGS.new_weigth_path,\n",
    "                   size = FLAGS.size)\n",
    "    print(f'Weight and Checkpoints files are created')\n",
    "else:\n",
    "    print(f'Weight and Checkpoints files existed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1278b1",
   "metadata": {},
   "source": [
    "# Get the Dataset from Crisis NLP\n",
    "### Deep Learning Benchmarks and Datasets for Social Media Image Classification for Disaster Response<br>\n",
    "\n",
    "The complete dataset contains 4 Tasks:\n",
    "<br> &emsp;&emsp;(a) Disaster types \n",
    "<br> &emsp;&emsp;(b) Informativeness\n",
    "<br> &emsp;&emsp;(c) Humanitarian categories\n",
    "<br> &emsp;&emsp;(d) Damage severity\n",
    "\n",
    "Sub-datasets below will be used by Task (a) and Task (c) \n",
    "<br> &emsp;&emsp;(i) AIDR\n",
    "<br> &emsp;&emsp;(ii) CrisisMMD\n",
    "<br> &emsp;&emsp;(iii) DamageMultimodal\n",
    "\n",
    "Sub-dataset for Task (a) and Task (c) will be used to train each of the tasks seperately <br>\n",
    "\n",
    "**Reference:**<br>\n",
    "https://crisisnlp.qcri.org/crisis-image-datasets-asonam20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "799ee808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been downloaded\n"
     ]
    }
   ],
   "source": [
    "# get the tar gz file\n",
    "# https://www.youtube.com/watch?v=U-nsgM9XWtU&list=PLpoCVQU4m6j_jNSbNFBeyT-tchsbc3CLV&index=3\n",
    "_path = os.path.join(FLAGS.root, 'crisis_vision_benchmarks.tar.gz')\n",
    "if not os.path.isfile(_path):\n",
    "    t1 = timeit.default_timer()\n",
    "    !wget --tries=30 https://crisisnlp.qcri.org/data/crisis_image_datasets_benchmarks/crisis_vision_benchmarks.tar.gz\n",
    "    #!wget --continue --progress=dot:mega --tries=0 https://crisisnlp.qcri.org/data/crisis_image_datasets_benchmarks/crisis_vision_benchmarks.tar.gz\n",
    "    t2 = timeit.default_timer()\n",
    "\n",
    "    clear_output()\n",
    "    print('Total time to download the dataset: {:.2f} min'.format((t2-t1) / 60))\n",
    "else:\n",
    "    print('Dataset has been downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d90ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been extracted\n"
     ]
    }
   ],
   "source": [
    "# extract the tar gz file using previous tutorial\n",
    "data_root = os.path.join(FLAGS.root, 'crisis_vision_benchmarks')\n",
    "if not os.path.isdir(data_root):\n",
    "    t1 = timeit.default_timer()\n",
    "    !tar --gunzip --extract --verbose --file=crisis_vision_benchmarks.tar.gz\n",
    "    t2 = timeit.default_timer()\n",
    "\n",
    "    clear_output()\n",
    "    print('Total time to extract the dataset: {:.2f} min'.format((t2-t1) / 60))\n",
    "else:\n",
    "    print(\"Dataset has been extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1034530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files are not deleted first\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    # remove the tar gz file to save space\n",
    "    os.remove(os.path.join(FLAGS.root, 'crisis_vision_benchmarks.tar.gz'))\n",
    "    # remove additional dataset\n",
    "    shutil.rmtree(os.path.join(FLAGS.root, 'crisis_vision_benchmarks/data/ASONAM17_Damage_Image_Dataset'))\n",
    "    shutil.rmtree(os.path.join(FLAGS.root, 'crisis_vision_benchmarks/data/aidr_info'))\n",
    "else:\n",
    "    print('The files are not deleted first')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
